{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basedir = \"C:/Users/D072202/DeepAnyMatch/DeepAnyMatch/result_data/oaei/OAEI_w2v_steps_walklength1_3grams_2019_06_17_23_44_39_385507/\"\n",
    "\n",
    "gs = pd.read_csv(basedir+\"oaei_gold_standard5best.csv\", encoding=\"UTF-8\", sep=\"\\t\", header=None)\n",
    "gs.columns = ['src_id','tgt_id','prediction']\n",
    "embs = pd.read_csv(basedir+\"stratified_embeddings.csv\", encoding=\"UTF-8\", sep=\",\")\n",
    "embs = embs[[col for col in embs.columns if re.match('x\\d+', col) is not None]+['label']]\n",
    "embs.columns = [\"src_\" + str(col) for col in [re.search(\"\\d+\", col).group(0) for col in embs.columns if re.match('x\\d+', col) is not None]] + ['label']\n",
    "gs = gs.merge(embs, left_on=['src_id'], right_on=['label'])\n",
    "embs.columns = [\"tgt_\" + str(col) for col in [re.search(\"\\d+\", col).group(0) for col in embs.columns if re.match('src_\\d+', col) is not None]] + ['label']\n",
    "gs = gs.merge(embs, left_on=['tgt_id'], right_on=['label'])\n",
    "gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origindir = \"C:/Users/D072202/DeepAnyMatch/DeepAnyMatch/data/oaei_data/\"\n",
    "labels1 = dict()\n",
    "categories1 = dict()\n",
    "with open(origindir+\"graph_triples_oldschoolrunescape.nt\", encoding=\"UTF-8\", mode=\"r\") as f:\n",
    "    for line in f:\n",
    "        if '<http://www.w3.org/2000/01/rdf-schema#label>' in line:\n",
    "            line = line.replace(\"<\",\"\").replace(\">\",\"\").replace(\" .\\n\",\"\").split(\" http://www.w3.org/2000/01/rdf-schema#label \")\n",
    "            labels1[line[0]] = line[1]\n",
    "        if '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>' in line:\n",
    "            line = line.replace(\"<\",\"\").replace(\">\",\"\").replace(\" .\\n\",\"\").split(\" http://www.w3.org/1999/02/22-rdf-syntax-ns#type \")\n",
    "            if line[1] not in ['http://www.w3.org/2002/07/owl#class','http://www.w3.org/1999/02/22-rdf-syntax-ns#property']:\n",
    "                categories1[line[0]] = 'resource'\n",
    "            else:\n",
    "                categories1[line[0]] = line[1]\n",
    "labels2 = dict()\n",
    "categories2 = dict()\n",
    "with open(origindir+\"graph_triples_darkscape.nt\", encoding=\"UTF-8\", mode=\"r\") as f:\n",
    "    for line in f:\n",
    "        if '<http://www.w3.org/2000/01/rdf-schema#label>' in line:\n",
    "            line = line.replace(\"<\",\"\").replace(\">\",\"\").replace(\" .\\n\",\"\").split(\" http://www.w3.org/2000/01/rdf-schema#label \")\n",
    "            labels2[line[0]] = line[1]\n",
    "        if '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>' in line:\n",
    "            line = line.replace(\"<\",\"\").replace(\">\",\"\").replace(\" .\\n\",\"\").split(\" http://www.w3.org/1999/02/22-rdf-syntax-ns#type \")\n",
    "            if line[1] not in ['http://www.w3.org/2002/07/owl#class','http://www.w3.org/1999/02/22-rdf-syntax-ns#property']:\n",
    "                categories2[line[0]] = 'resource'\n",
    "            else:\n",
    "                categories2[line[0]] = line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories1['http://dbkwik.webdatacommons.org/oldschoolrunescape/class/switch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.loc[:,'src_category'] = 'resource'\n",
    "gs.loc[:,'tgt_category'] = 'resource'\n",
    "for index, row in gs.iterrows():\n",
    "    try:\n",
    "        gs.loc[index, 'src_category'] = categories1[row['src_id']]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        gs.loc[index, 'tgt_category'] = categories2[row['tgt_id']]\n",
    "    except KeyError:\n",
    "        pass\n",
    "gs = gs.loc[gs.src_category == gs.tgt_category]\n",
    "len(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.loc[gs.src_id=='http://dbkwik.webdatacommons.org/darkscape/resource/ancient_magicks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import *\n",
    "def extend_features(df):\n",
    "    src_pattern = \"src_\\d+\"\n",
    "    tgt_pattern = \"tgt_\\d+\"\n",
    "    src_dim = int(len([elem for elem in [re.match(src_pattern, elem) is not None for elem in df.columns.values.tolist()] if elem==True]))\n",
    "    tgt_dim = int(len([elem for elem in [re.match(tgt_pattern, elem) is not None for elem in df.columns.values.tolist()] if elem==True]))\n",
    "\n",
    "\n",
    "    def dotproduct(v1, v2):\n",
    "        result = list()\n",
    "        for i in range(len(v1)):\n",
    "            result.append([np.dot(v1[i], v2[i])])\n",
    "        return np.array(result)\n",
    "\n",
    "    def length(v):\n",
    "        return np.sqrt(dotproduct(v, v))\n",
    "\n",
    "    def angle(v1, v2):\n",
    "        return np.arctan(dotproduct(v1, v2) / (length(v1) * length(v2)))\n",
    "\n",
    "    a = np.array(df[[\"src_\" + str(i) for i in range(src_dim)]].values.tolist())\n",
    "    b = np.array(df[[\"tgt_\" + str(i) for i in range(tgt_dim)]].values.tolist())\n",
    "    print(\".\")\n",
    "    df['src_tgt_angle'] = paired_cosine_distances(a, b)\n",
    "    print(\".\")\n",
    "    #src_origin = np.full((len(df), src_dim), 0.0000001)\n",
    "    #tgt_origin = np.full((len(df), tgt_dim), 0.0000001)\n",
    "    #df['src_angle_to_origin'] = cosine_similarity(tgt_origin,a).diagonal()\n",
    "    #print(\".\")\n",
    "    #df['tgt_angle_to_origin'] = cosine_similarity(src_origin,b).diagonal()\n",
    "    df['src_veclen'] = length(a)\n",
    "    df['tgt_veclen'] = length(b)\n",
    "    df['src_tgt_veclen'] = paired_euclidean_distances(a,b)#.diagonal()#length(a-b)\n",
    "    df.head()\n",
    "    \n",
    "    df.fillna(0, inplace = True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9843"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = extend_features(gs)\n",
    "len(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "memo = {}\n",
    "\n",
    "def lev(s,t, n=3):\n",
    "    s = labels1[s]\n",
    "    t = labels2[t]\n",
    "    t = set([t[i:i+n] for i in range(len(t)-n+1)])\n",
    "    s = set([s[i:i+n] for i in range(len(s)-n+1)])\n",
    "    return 1-len([gram for gram in s if gram in t])/max(len(s), len(t))\n",
    "    #return levenshtein(s,t)/max(len(s),len(t))\n",
    "\n",
    "def levenshtein(s, t):\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    cost = 0 if s[-1] == t[-1] else 1\n",
    "\n",
    "    i1 = (s[:-1], t)\n",
    "    if not i1 in memo:\n",
    "        memo[i1] = levenshtein(*i1)\n",
    "    i2 = (s, t[:-1])\n",
    "    if not i2 in memo:\n",
    "        memo[i2] = levenshtein(*i2)\n",
    "    i3 = (s[:-1], t[:-1])\n",
    "    if not i3 in memo:\n",
    "        memo[i3] = levenshtein(*i3)\n",
    "    res = min([memo[i1]+1, memo[i2]+1, memo[i3]+cost])\n",
    "\n",
    "    return res\n",
    "gs['syntactic_diff'] = gs.apply(lambda row: lev(row['src_id'], row['tgt_id']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "oaei_gold_standard3 = pd.read_csv(basedir+\"oaei_gold_standard2.csv_merged.csv\",sep=\"\\t\",encoding=\"UTF-8\")\n",
    "\n",
    "cols = ['syntactic_diff']#[col for col in oaei_gold_standard3.columns if col not in ['label','Unnamed: 0','src_id','tgt_id','src_category','tgt_category','src_angle_to_origin','tgt_angle_to_origin']]#['src_tgt_angle', 'src_tgt_veclen', 'plus_diff', 'syntactic_diff']\n",
    "X, y = oaei_gold_standard3[cols], oaei_gold_standard3.label\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0).fit(X,y)\n",
    "#XGBClassifier().fit(X, y)\n",
    "        #random_state=0, solver='lbfgs', multi_class='ovr', class_weight={1:0.1,0:0.9}).fit(X, y)\n",
    "\n",
    "X = gs[cols]\n",
    "matchings = gs.loc[clf.predict(X)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8601"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = matchings\n",
    "len(matchings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(gs.src_id))\n",
    "from gensim.models import Doc2Vec, Word2Vec\n",
    "model = Word2Vec.load(basedir+\"w2v.model\")\n",
    "#def get_training_material(nid):\n",
    "#            res = list()\n",
    "#            with open(basedir+\"w2v_training_material.csv\", mode=\"r\", encoding=\"UTF-8\") as f:\n",
    "#                for line in f:\n",
    "#                    if nodeid in line.split(\" \"):\n",
    "#                        res = res + line.split(\" \")\n",
    "#                return list(set(res))\n",
    "\n",
    "def mergedf(df1, df2):\n",
    "            if df1 is None:\n",
    "                return df2\n",
    "            else:\n",
    "                return df1.append(df2, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_id</th>\n",
       "      <th>tgt_id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>src_0</th>\n",
       "      <th>src_1</th>\n",
       "      <th>src_2</th>\n",
       "      <th>src_3</th>\n",
       "      <th>src_4</th>\n",
       "      <th>src_5</th>\n",
       "      <th>src_6</th>\n",
       "      <th>...</th>\n",
       "      <th>tgt_18</th>\n",
       "      <th>tgt_19</th>\n",
       "      <th>label_y</th>\n",
       "      <th>src_category</th>\n",
       "      <th>tgt_category</th>\n",
       "      <th>src_tgt_angle</th>\n",
       "      <th>src_veclen</th>\n",
       "      <th>tgt_veclen</th>\n",
       "      <th>src_tgt_veclen</th>\n",
       "      <th>syntactic_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.595992</td>\n",
       "      <td>-0.707725</td>\n",
       "      <td>-0.142509</td>\n",
       "      <td>0.916277</td>\n",
       "      <td>0.157136</td>\n",
       "      <td>-0.303571</td>\n",
       "      <td>0.332199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.809345</td>\n",
       "      <td>-0.202770</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>resource</td>\n",
       "      <td>resource</td>\n",
       "      <td>0.173316</td>\n",
       "      <td>3.408611</td>\n",
       "      <td>3.541964</td>\n",
       "      <td>2.050057</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.053435</td>\n",
       "      <td>0.253450</td>\n",
       "      <td>0.550742</td>\n",
       "      <td>1.592068</td>\n",
       "      <td>-0.378630</td>\n",
       "      <td>-0.120701</td>\n",
       "      <td>-0.987976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152555</td>\n",
       "      <td>0.032775</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>resource</td>\n",
       "      <td>resource</td>\n",
       "      <td>0.093063</td>\n",
       "      <td>3.980785</td>\n",
       "      <td>3.755103</td>\n",
       "      <td>1.683205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387422</td>\n",
       "      <td>-0.371901</td>\n",
       "      <td>-1.835802</td>\n",
       "      <td>0.073830</td>\n",
       "      <td>0.837599</td>\n",
       "      <td>-1.365538</td>\n",
       "      <td>0.198029</td>\n",
       "      <td>...</td>\n",
       "      <td>1.049903</td>\n",
       "      <td>0.281266</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>resource</td>\n",
       "      <td>resource</td>\n",
       "      <td>0.336289</td>\n",
       "      <td>3.582896</td>\n",
       "      <td>3.800261</td>\n",
       "      <td>3.033981</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503127</td>\n",
       "      <td>-0.873779</td>\n",
       "      <td>-0.421261</td>\n",
       "      <td>1.295298</td>\n",
       "      <td>-0.118796</td>\n",
       "      <td>-0.769945</td>\n",
       "      <td>-1.092250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332775</td>\n",
       "      <td>0.321395</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>resource</td>\n",
       "      <td>resource</td>\n",
       "      <td>0.142006</td>\n",
       "      <td>3.440545</td>\n",
       "      <td>3.249102</td>\n",
       "      <td>1.792076</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.187986</td>\n",
       "      <td>-0.406288</td>\n",
       "      <td>0.738584</td>\n",
       "      <td>1.686720</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>0.201873</td>\n",
       "      <td>-0.961155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863415</td>\n",
       "      <td>0.773165</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>resource</td>\n",
       "      <td>resource</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>3.604995</td>\n",
       "      <td>4.094606</td>\n",
       "      <td>1.225255</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              src_id  \\\n",
       "0  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "1  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "2  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "3  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "4  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "\n",
       "                                              tgt_id  prediction     src_0  \\\n",
       "0  http://dbkwik.webdatacommons.org/darkscape/res...           1  0.595992   \n",
       "1  http://dbkwik.webdatacommons.org/darkscape/res...           1 -0.053435   \n",
       "2  http://dbkwik.webdatacommons.org/darkscape/res...           1  0.387422   \n",
       "3  http://dbkwik.webdatacommons.org/darkscape/res...           1  0.503127   \n",
       "4  http://dbkwik.webdatacommons.org/darkscape/res...           1  0.187986   \n",
       "\n",
       "      src_1     src_2     src_3     src_4     src_5     src_6  ...    tgt_18  \\\n",
       "0 -0.707725 -0.142509  0.916277  0.157136 -0.303571  0.332199  ... -0.809345   \n",
       "1  0.253450  0.550742  1.592068 -0.378630 -0.120701 -0.987976  ... -0.152555   \n",
       "2 -0.371901 -1.835802  0.073830  0.837599 -1.365538  0.198029  ...  1.049903   \n",
       "3 -0.873779 -0.421261  1.295298 -0.118796 -0.769945 -1.092250  ...  0.332775   \n",
       "4 -0.406288  0.738584  1.686720 -0.001722  0.201873 -0.961155  ...  0.863415   \n",
       "\n",
       "     tgt_19                                            label_y  src_category  \\\n",
       "0 -0.202770  http://dbkwik.webdatacommons.org/darkscape/res...      resource   \n",
       "1  0.032775  http://dbkwik.webdatacommons.org/darkscape/res...      resource   \n",
       "2  0.281266  http://dbkwik.webdatacommons.org/darkscape/res...      resource   \n",
       "3  0.321395  http://dbkwik.webdatacommons.org/darkscape/res...      resource   \n",
       "4  0.773165  http://dbkwik.webdatacommons.org/darkscape/res...      resource   \n",
       "\n",
       "   tgt_category  src_tgt_angle  src_veclen  tgt_veclen  src_tgt_veclen  \\\n",
       "0      resource       0.173316    3.408611    3.541964        2.050057   \n",
       "1      resource       0.093063    3.980785    3.755103        1.683205   \n",
       "2      resource       0.336289    3.582896    3.800261        3.033981   \n",
       "3      resource       0.142006    3.440545    3.249102        1.792076   \n",
       "4      resource       0.042732    3.604995    4.094606        1.225255   \n",
       "\n",
       "   syntactic_diff  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Computing rank-features: 0%.\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D072202\\AppData\\Local\\Continuum\\anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\D072202\\AppData\\Local\\Continuum\\anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Computing rank-features: 73%.\r"
     ]
    }
   ],
   "source": [
    "progress = 0\n",
    "matchings = None\n",
    "total = len(set(gs.src_id))\n",
    "for nodeid in set(gs.src_id):#.union(gs.tgt_id)\n",
    "                possible_matches_for_nodeid = gs.loc[(gs.src_id==nodeid) ]\n",
    "        \n",
    "                #possible_matches.loc[((possible_matches.src_id==nodeid) & (possible_matches.tgt_id.isin(get_possible_matches(nodeid))))]\n",
    "\n",
    "\n",
    "\n",
    "                progress += 1\n",
    "                if len(possible_matches_for_nodeid)<1:\n",
    "                    continue\n",
    "                \n",
    "                #print(str(progress), end=\"\\r\")\n",
    "                print(\"         Computing rank-features: \" + str(int(100*progress/total)) + \"%.\", end='\\r')\n",
    "                # In[312]:\n",
    "\n",
    "\n",
    "\n",
    "                #model.docvecs.most_similar(0)\n",
    "\n",
    "\n",
    "                # In[313]:\n",
    "\n",
    "\n",
    "                #print('Closest in general:')\n",
    "                #for val in model.docvecs.most_similar(i):\n",
    "                #    try:\n",
    "                #        print(documents_ids_A[int(val[0])])\n",
    "                #    except:\n",
    "                #        try:\n",
    "                #            print(documents_ids_B[int(val[0])])\n",
    "                #        except:\n",
    "                #            print(str(val[0]) + \" not found\")\n",
    "\n",
    "\n",
    "                # In[314]:\n",
    "\n",
    "\n",
    "                #print('Closest in terms of cosine similarity:')\n",
    "                #vecs = model.docvecs.doctag_syn0[np.array(get_possible_matches(nodeid))]\n",
    "                #vecs = model.wv[get_possible_matches(nodeid)]\n",
    "                #x = cosine_similarity(np.array([model.wv[nodeid]]), vecs)\n",
    "                #x = np.concatenate((x, np.array([get_possible_matches(nodeid)])), axis=0)\n",
    "                #sorted_x = pd.DataFrame(x).T.sort_values(by=[0], ascending=False)\n",
    "                #sorted_x.loc[:,'cos_score'] = 0\n",
    "                ctr = 1\n",
    "                #sorted_x.columns = ['cos_sim' if col==0 else col for col in sorted_x.columns]\n",
    "                #sorted_x.columns = ['cos_sim' if col==0 else col for col in sorted_x.columns]\n",
    "                #sorted_x['cos_sim'] = sorted_x['cos_sim'].astype('float64')\n",
    "                sorted_x = possible_matches_for_nodeid.sort_values(by=['src_tgt_angle'], ascending=False)\n",
    "                sorted_x.loc[:,'cos_score'] = 0\n",
    "                maximum = sorted_x.head(1).src_tgt_angle.values[0]\n",
    "                sorted_x.loc[:,'diff_to_max'] = 1.0 - sorted_x.loc[:, 'src_tgt_angle'] / maximum\n",
    "                for index, row in sorted_x.iterrows():\n",
    "                    #print(row[1] + \" - \" + str(row['cos_sim']))\n",
    "                    sorted_x.loc[index, 'cos_score'] = row['cos_score'] + 1/ctr\n",
    "                    ctr += 1\n",
    "\n",
    "\n",
    "                # In[315]:\n",
    "\n",
    "\n",
    "                #print('Closest in terms of Euclidean distance:')print('Closest in terms of Euclidean distance:')\n",
    "                sorted_x2 = sorted_x\n",
    "                #vecs = model.wv[get_possible_matches(nodeid)]\n",
    "                #x = euclidean_distances(np.array([model.wv[nodeid]]), vecs)\n",
    "                #x = np.concatenate((x, np.array([get_possible_matches(nodeid)])), axis=0)\n",
    "                #sorted_x = pd.DataFrame(x).T.sort_values(by=[0], ascending=True)\n",
    "                sorted_x = possible_matches_for_nodeid.sort_values(by=['src_tgt_veclen'], ascending=True)\n",
    "                sorted_x.loc[:,'euclid_score'] = 0\n",
    "                ctr = 1\n",
    "                #sorted_x.columns = ['euclid_sim' if col==0 else col for col in sorted_x.columns]\n",
    "                for index, row in sorted_x.iterrows():\n",
    "                    #print(row[1] + \" - \" + str(row['euclid_sim']))\n",
    "                    sorted_x.loc[index, 'euclid_score'] = row['euclid_score'] + 1/ctr\n",
    "                    ctr += 1\n",
    "\n",
    "\n",
    "\n",
    "                ##print('Closest in terms of syntax:')\n",
    "                #sorted_x3 = sorted_x\n",
    "                ##vecs = model.wv[get_possible_matches(nodeid)]\n",
    "                #def edits(v1, v2s):\n",
    "                #    res = list()\n",
    "                #    v1 = v1.split(\"/\")[-1]\n",
    "                #    for v2 in v2s:\n",
    "                #        v2 = v2.split(\"/\")[-1]\n",
    "                #        res.append(editdistance.eval(v1, v2)/min(len(v1), len(v2)))\n",
    "                #    return np.array([res])\n",
    "                ##x = edits(nodeid, get_possible_matches(nodeid))\n",
    "                ##x = np.concatenate((x, np.array([get_possible_matches(nodeid)])), axis=0)\n",
    "                ##sorted_x = pd.DataFrame(x).T.sort_values(by=[0], ascending=True)\n",
    "                #sorted_x = possible_matches_for_nodeid.sort_values(by=['syntactic_diff'], ascending=True)\n",
    "                #sorted_x.loc[:,'syntax_score'] = 0\n",
    "                #ctr = 1\n",
    "                ##sorted_x.columns = ['syntax_diff' if col==0 else col for col in sorted_x.columns]\n",
    "                #for index, row in sorted_x.iterrows():\n",
    "                #    #print(row[1] + \" - \" + str(row['syntax_diff']))\n",
    "                #    sorted_x.loc[index, 'syntax_score'] = row['syntax_score'] + 1/ctr\n",
    "                #    ctr += 1\n",
    "\n",
    "\n",
    "\n",
    "                sorted_x3 = sorted_x\n",
    "                sorted_x = possible_matches_for_nodeid\n",
    "                ctr = 1\n",
    "                sorted_x.loc[:,'probability_score'] = 0\n",
    "                sorted_x.loc[:,'probability'] = 0\n",
    "                #print('Closest in terms of output probability:')\n",
    "                #for tuple in model.predict_output_word(get_training_material(nodeid), topn=99999999):\n",
    "                #    if tuple[0] in possible_matches_for_nodeid.tgt_id.to_list():\n",
    "                #        sorted_x.loc[sorted_x.tgt_id==tuple[0], 'probability'] = float(tuple[1])\n",
    "                #        sorted_x.loc[sorted_x.tgt_id==tuple[0], 'probability_score'] = 1/ctr\n",
    "                #        ctr = ctr + 1\n",
    "\n",
    "\n",
    "                # In[316]:\n",
    "\n",
    "\n",
    "                #print('Closest in sum:')\n",
    "                x = sorted_x[['probability_score','probability']].merge(sorted_x3['euclid_score'].to_frame().merge(sorted_x2, left_index=True, right_index=True), left_index=True, right_index=True)\n",
    "                x.loc[:,'total_score'] = x['cos_score'] + x['euclid_score'] + x['probability_score']\n",
    "                sorted_x = x.sort_values(by=['total_score'], ascending=False)\n",
    "                #sorted_x.columns = ['tgt_id' if col==1 else col for col in sorted_x.columns]\n",
    "                for index, row in sorted_x.iterrows():#sorted_x.loc[sorted_x.total_score == max(sorted_x.total_score.values),:].iterrows():\n",
    "                    matching_pair = pd.DataFrame([sorted_x.loc[index]])\n",
    "                    matching_pair.loc[:,'src_id'] = nodeid\n",
    "                    #print(nodeid + \"\\t\" + row[1] + \"\\t\" + str(row['total_score']) + \"\\t\" + str(row['cos_score']) + \"\\t\" + str(row['euclid_score']))\n",
    "                    matchings = mergedf(matchings, matching_pair)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchings_saved=matchings\n",
    "matchings = matchings.sort_values(by=['total_score','syntactic_diff'], ascending=[False, True])\n",
    "married_matchings = None\n",
    "ctr = 0\n",
    "while len(matchings) > 0:\n",
    "                ctr += 1\n",
    "                row = matchings.head(1)\n",
    "                married_matchings = mergedf(married_matchings, pd.DataFrame(row))\n",
    "                matchings = matchings.loc[~(matchings.src_id == row.src_id.values[0]) & ~(matchings.tgt_id == row.tgt_id.values[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-789156b0b81a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrelevants\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mgold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmarried_matches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmarried_matchings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'src_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrelevants\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tgt_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrelevants\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mmarried_matches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmergedf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarried_matches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "gold = pd.read_csv(origindir+\"gold_standard.csv\",encoding=\"UTF-8\",sep=\"\\t\", header=None)\n",
    "relevants = set(gold[0].to_list()+gold[1].to_list())\n",
    "married_matches = None\n",
    "for index, row in married_matchings.iterrows():\n",
    "        if row['src_id'] in relevants and row['tgt_id'] in relevants:\n",
    "            married_matches = mergedf(married_matches, pd.DataFrame(row).transpose())\n",
    "married_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def create_elem(src_id, tgt_id):\n",
    "    elem = '<map>\\n<Cell>\\n<entity1 rdf:resource=\"'+src_id+'\"/>\\n'\n",
    "    elem = elem + '<entity2 rdf:resource=\"'+tgt_id+'\"/>\\n<relation>=</relation>\\n'\n",
    "    elem = elem + '<measure rdf:datatype=\"xsd:float\">1.0</measure>\\n</Cell>\\n</map>'\n",
    "    return elem\n",
    "\n",
    "matchings_filename =\"married_matchings.csv\"\n",
    "#married_matches = pd.read_csv(basedir + matchings_filename, sep=\"\\t\", encoding=\"UTF-8\")\n",
    "starttag = '<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<rdf:RDF xmlns=\"http://knowledgeweb.semanticweb.org/heterogeneity/alignment\"\\n  xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\\n  xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\">\\n<Alignment>\\n  <xml>yes</xml>\\n  <level>0</level>\\n  <type>??</type>\\n  <onto1>\\n    <Ontology rdf:about=\"darkscape\">\\n      <location>http://darkscape.wikia.com</location>\\n    </Ontology>\\n  </onto1>\\n  <onto2>\\n    <Ontology rdf:about=\"oldschoolrunescape\">\\n      <location>http://oldschoolrunescape.wikia.com</location>\\n    </Ontology>\\n  </onto2>\\n'\n",
    "endtag = '</Alignment>\\n</rdf:RDF>'\n",
    "#os.mkdir(basedir + matchings_filename.replace(\".csv\",\"\"))\n",
    "with open(basedir + matchings_filename.replace(\".csv\",\"\") + str(os.sep) + 'darkscape~oldschoolrunescape~results.xml', \"w+\", encoding=\"UTF-8\") as f:\n",
    "        f.write(starttag)\n",
    "        for index, row in married_matchings.iterrows():\n",
    "            f.write(create_elem(str(row.src_id).replace(\"&\",\"&amp;\"), str(row.tgt_id).replace(\"&\",\"&amp;\"))+\"\\n\")\n",
    "        f.write(endtag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
