{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_id</th>\n",
       "      <th>tgt_id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>src_0</th>\n",
       "      <th>src_1</th>\n",
       "      <th>src_2</th>\n",
       "      <th>src_3</th>\n",
       "      <th>src_4</th>\n",
       "      <th>src_5</th>\n",
       "      <th>src_6</th>\n",
       "      <th>...</th>\n",
       "      <th>tgt_11</th>\n",
       "      <th>tgt_12</th>\n",
       "      <th>tgt_13</th>\n",
       "      <th>tgt_14</th>\n",
       "      <th>tgt_15</th>\n",
       "      <th>tgt_16</th>\n",
       "      <th>tgt_17</th>\n",
       "      <th>tgt_18</th>\n",
       "      <th>tgt_19</th>\n",
       "      <th>label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.595992</td>\n",
       "      <td>-0.707725</td>\n",
       "      <td>-0.142509</td>\n",
       "      <td>0.916277</td>\n",
       "      <td>0.157136</td>\n",
       "      <td>-0.303571</td>\n",
       "      <td>0.332199</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.009639</td>\n",
       "      <td>-0.593065</td>\n",
       "      <td>1.176588</td>\n",
       "      <td>1.495856</td>\n",
       "      <td>1.107529</td>\n",
       "      <td>-1.159641</td>\n",
       "      <td>0.270346</td>\n",
       "      <td>-0.809345</td>\n",
       "      <td>-0.202770</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.595992</td>\n",
       "      <td>-0.707725</td>\n",
       "      <td>-0.142509</td>\n",
       "      <td>0.916277</td>\n",
       "      <td>0.157136</td>\n",
       "      <td>-0.303571</td>\n",
       "      <td>0.332199</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.009639</td>\n",
       "      <td>-0.593065</td>\n",
       "      <td>1.176588</td>\n",
       "      <td>1.495856</td>\n",
       "      <td>1.107529</td>\n",
       "      <td>-1.159641</td>\n",
       "      <td>0.270346</td>\n",
       "      <td>-0.809345</td>\n",
       "      <td>-0.202770</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.595992</td>\n",
       "      <td>-0.707725</td>\n",
       "      <td>-0.142509</td>\n",
       "      <td>0.916277</td>\n",
       "      <td>0.157136</td>\n",
       "      <td>-0.303571</td>\n",
       "      <td>0.332199</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.009639</td>\n",
       "      <td>-0.593065</td>\n",
       "      <td>1.176588</td>\n",
       "      <td>1.495856</td>\n",
       "      <td>1.107529</td>\n",
       "      <td>-1.159641</td>\n",
       "      <td>0.270346</td>\n",
       "      <td>-0.809345</td>\n",
       "      <td>-0.202770</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.595992</td>\n",
       "      <td>-0.707725</td>\n",
       "      <td>-0.142509</td>\n",
       "      <td>0.916277</td>\n",
       "      <td>0.157136</td>\n",
       "      <td>-0.303571</td>\n",
       "      <td>0.332199</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.009639</td>\n",
       "      <td>-0.593065</td>\n",
       "      <td>1.176588</td>\n",
       "      <td>1.495856</td>\n",
       "      <td>1.107529</td>\n",
       "      <td>-1.159641</td>\n",
       "      <td>0.270346</td>\n",
       "      <td>-0.809345</td>\n",
       "      <td>-0.202770</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595992</td>\n",
       "      <td>-0.707725</td>\n",
       "      <td>-0.142509</td>\n",
       "      <td>0.916277</td>\n",
       "      <td>0.157136</td>\n",
       "      <td>-0.303571</td>\n",
       "      <td>0.332199</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.238957</td>\n",
       "      <td>-0.444669</td>\n",
       "      <td>0.245949</td>\n",
       "      <td>1.383596</td>\n",
       "      <td>0.363228</td>\n",
       "      <td>0.409382</td>\n",
       "      <td>-0.186877</td>\n",
       "      <td>-0.376917</td>\n",
       "      <td>0.786189</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              src_id  \\\n",
       "0  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "1  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "2  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "3  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "4  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "\n",
       "                                              tgt_id  prediction     src_0  \\\n",
       "0  http://dbkwik.webdatacommons.org/darkscape/res...           1  0.595992   \n",
       "1  http://dbkwik.webdatacommons.org/darkscape/res...           1  0.595992   \n",
       "2  http://dbkwik.webdatacommons.org/darkscape/res...           1  0.595992   \n",
       "3  http://dbkwik.webdatacommons.org/darkscape/res...           1  0.595992   \n",
       "4  http://dbkwik.webdatacommons.org/darkscape/res...           0  0.595992   \n",
       "\n",
       "      src_1     src_2     src_3     src_4     src_5     src_6  ...    tgt_11  \\\n",
       "0 -0.707725 -0.142509  0.916277  0.157136 -0.303571  0.332199  ... -1.009639   \n",
       "1 -0.707725 -0.142509  0.916277  0.157136 -0.303571  0.332199  ... -1.009639   \n",
       "2 -0.707725 -0.142509  0.916277  0.157136 -0.303571  0.332199  ... -1.009639   \n",
       "3 -0.707725 -0.142509  0.916277  0.157136 -0.303571  0.332199  ... -1.009639   \n",
       "4 -0.707725 -0.142509  0.916277  0.157136 -0.303571  0.332199  ... -1.238957   \n",
       "\n",
       "     tgt_12    tgt_13    tgt_14    tgt_15    tgt_16    tgt_17    tgt_18  \\\n",
       "0 -0.593065  1.176588  1.495856  1.107529 -1.159641  0.270346 -0.809345   \n",
       "1 -0.593065  1.176588  1.495856  1.107529 -1.159641  0.270346 -0.809345   \n",
       "2 -0.593065  1.176588  1.495856  1.107529 -1.159641  0.270346 -0.809345   \n",
       "3 -0.593065  1.176588  1.495856  1.107529 -1.159641  0.270346 -0.809345   \n",
       "4 -0.444669  0.245949  1.383596  0.363228  0.409382 -0.186877 -0.376917   \n",
       "\n",
       "     tgt_19                                            label_y  \n",
       "0 -0.202770  http://dbkwik.webdatacommons.org/darkscape/res...  \n",
       "1 -0.202770  http://dbkwik.webdatacommons.org/darkscape/res...  \n",
       "2 -0.202770  http://dbkwik.webdatacommons.org/darkscape/res...  \n",
       "3 -0.202770  http://dbkwik.webdatacommons.org/darkscape/res...  \n",
       "4  0.786189  http://dbkwik.webdatacommons.org/darkscape/res...  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basedir = \"C:/Users/D072202/DeepAnyMatch/DeepAnyMatch/result_data/oaei/OAEI_w2v_steps_walklength1_3grams_2019_06_17_23_44_39_385507/\"\n",
    "\n",
    "gs = pd.read_csv(basedir+\"oaei_gold_standard.csv\", encoding=\"UTF-8\", sep=\"\\t\", header=None)\n",
    "gs.columns = ['src_id','tgt_id','prediction']\n",
    "embs = pd.read_csv(basedir+\"stratified_embeddings.csv\", encoding=\"UTF-8\", sep=\",\")\n",
    "embs = embs[[col for col in embs.columns if re.match('x\\d+', col) is not None]+['label']]\n",
    "embs.columns = [\"src_\" + str(col) for col in [re.search(\"\\d+\", col).group(0) for col in embs.columns if re.match('x\\d+', col) is not None]] + ['label']\n",
    "gs = gs.merge(embs, left_on=['src_id'], right_on=['label'])\n",
    "embs.columns = [\"tgt_\" + str(col) for col in [re.search(\"\\d+\", col).group(0) for col in embs.columns if re.match('src_\\d+', col) is not None]] + ['label']\n",
    "gs = gs.merge(embs, left_on=['tgt_id'], right_on=['label'])\n",
    "gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import *\n",
    "def extend_features(df):\n",
    "    src_pattern = \"src_\\d+\"\n",
    "    tgt_pattern = \"tgt_\\d+\"\n",
    "    src_dim = int(len([elem for elem in [re.match(src_pattern, elem) is not None for elem in df.columns.values.tolist()] if elem==True]))\n",
    "    tgt_dim = int(len([elem for elem in [re.match(tgt_pattern, elem) is not None for elem in df.columns.values.tolist()] if elem==True]))\n",
    "\n",
    "\n",
    "    def dotproduct(v1, v2):\n",
    "        result = list()\n",
    "        for i in range(len(v1)):\n",
    "            result.append([np.dot(v1[i], v2[i])])\n",
    "        return np.array(result)\n",
    "\n",
    "    def length(v):\n",
    "        return np.sqrt(dotproduct(v, v))\n",
    "\n",
    "    def angle(v1, v2):\n",
    "        return np.arctan(dotproduct(v1, v2) / (length(v1) * length(v2)))\n",
    "\n",
    "    a = np.array(df[[\"src_\" + str(i) for i in range(src_dim)]].values.tolist())\n",
    "    b = np.array(df[[\"tgt_\" + str(i) for i in range(tgt_dim)]].values.tolist())\n",
    "    print(\".\")\n",
    "    df['src_tgt_angle'] = paired_cosine_distances(a, b)\n",
    "    print(\".\")\n",
    "    #src_origin = np.full((len(df), src_dim), 0.0000001)\n",
    "    #tgt_origin = np.full((len(df), tgt_dim), 0.0000001)\n",
    "    #df['src_angle_to_origin'] = cosine_similarity(tgt_origin,a).diagonal()\n",
    "    #print(\".\")\n",
    "    #df['tgt_angle_to_origin'] = cosine_similarity(src_origin,b).diagonal()\n",
    "    df['src_veclen'] = length(a)\n",
    "    df['tgt_veclen'] = length(b)\n",
    "    df['src_tgt_veclen'] = paired_euclidean_distances(a,b)#.diagonal()#length(a-b)\n",
    "    df.head()\n",
    "\n",
    "    df.fillna(0, inplace = True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "109220"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = extend_features(gs)\n",
    "len(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "memo = {}\n",
    "labels1 = dict()\n",
    "origindir = \"C:/Users/D072202/DeepAnyMatch/DeepAnyMatch/data/oaei_data/\"\n",
    "with open(origindir+\"graph_triples_oldschoolrunescape.nt\", encoding=\"UTF-8\", mode=\"r\") as f:\n",
    "    for line in f:\n",
    "        if '<http://www.w3.org/2000/01/rdf-schema#label>' in line:\n",
    "            line = line.replace(\"<\",\"\").replace(\">\",\"\").split(\" http://www.w3.org/2000/01/rdf-schema#label \")\n",
    "            labels1[line[0]] = line[1]\n",
    "labels2 = dict()\n",
    "with open(origindir+\"graph_triples_darkscape.nt\", encoding=\"UTF-8\", mode=\"r\") as f:\n",
    "    for line in f:\n",
    "        if '<http://www.w3.org/2000/01/rdf-schema#label>' in line:\n",
    "            line = line.replace(\"<\",\"\").replace(\">\",\"\").split(\" http://www.w3.org/2000/01/rdf-schema#label \")\n",
    "            labels2[line[0]] = line[1]\n",
    "\n",
    "def lev(s,t, n=3):\n",
    "    s = labels1[s]\n",
    "    t = labels2[t]\n",
    "    t = set([t[i:i+n] for i in range(len(t)-n+1)])\n",
    "    s = set([s[i:i+n] for i in range(len(s)-n+1)])\n",
    "    return 1-len([gram for gram in s if gram in t])/max(len(s), len(t))\n",
    "    #return levenshtein(s,t)/max(len(s),len(t))\n",
    "\n",
    "def levenshtein(s, t):\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    cost = 0 if s[-1] == t[-1] else 1\n",
    "\n",
    "    i1 = (s[:-1], t)\n",
    "    if not i1 in memo:\n",
    "        memo[i1] = levenshtein(*i1)\n",
    "    i2 = (s, t[:-1])\n",
    "    if not i2 in memo:\n",
    "        memo[i2] = levenshtein(*i2)\n",
    "    i3 = (s[:-1], t[:-1])\n",
    "    if not i3 in memo:\n",
    "        memo[i3] = levenshtein(*i3)\n",
    "    res = min([memo[i1]+1, memo[i2]+1, memo[i3]+cost])\n",
    "\n",
    "    return res\n",
    "gs['syntactic_diff'] = gs.apply(lambda row: lev(row['src_id'], row['tgt_id']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "oaei_gold_standard3 = pd.read_csv(basedir+\"oaei_gold_standard2.csv_merged.csv\",sep=\"\\t\",encoding=\"UTF-8\")\n",
    "\n",
    "cols = ['syntactic_diff']#[col for col in oaei_gold_standard3.columns if col not in ['label','Unnamed: 0','src_id','tgt_id','src_category','tgt_category','src_angle_to_origin','tgt_angle_to_origin']]#['src_tgt_angle', 'src_tgt_veclen', 'plus_diff', 'syntactic_diff']\n",
    "X, y = oaei_gold_standard3[cols], oaei_gold_standard3.label\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=3,random_state=0).fit(X,y)\n",
    "#XGBClassifier().fit(X, y)\n",
    "        #random_state=0, solver='lbfgs', multi_class='ovr', class_weight={1:0.1,0:0.9}).fit(X, y)\n",
    "\n",
    "X = gs[cols]\n",
    "matchings = gs.loc[clf.predict(X)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29870"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = matchings\n",
    "len(matchings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_training_material(nid):\n",
    "            res = list()\n",
    "            with open(basedir+\"w2v_training_material.csv\", mode=\"r\", encoding=\"UTF-8\") as f:\n",
    "                for line in f:\n",
    "                    if nodeid in line.split(\" \"):\n",
    "                        res = res + line.split(\" \")\n",
    "                return list(set(res))\n",
    "\n",
    "def mergedf(df1, df2):\n",
    "            if df1 is None:\n",
    "                return df2\n",
    "            else:\n",
    "                return df1.append(df2, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Computing rank-features: 0%.\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D072202\\AppData\\Local\\Continuum\\anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\D072202\\AppData\\Local\\Continuum\\anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Computing rank-features: 2%.\r"
     ]
    }
   ],
   "source": [
    "len(set(gs.src_id))\n",
    "from gensim.models import Doc2Vec, Word2Vec\n",
    "model = Word2Vec.load(basedir+\"w2v.model\")\n",
    "\n",
    "progress = 0\n",
    "matchings = None\n",
    "total = len(set(gs.src_id))\n",
    "for nodeid in set(gs.src_id):#.union(gs.tgt_id)\n",
    "                possible_matches_for_nodeid = gs.loc[gs.src_id==nodeid]\n",
    "                #possible_matches.loc[((possible_matches.src_id==nodeid) & (possible_matches.tgt_id.isin(get_possible_matches(nodeid))))]\n",
    "\n",
    "\n",
    "\n",
    "                progress += 1\n",
    "                if len(possible_matches_for_nodeid)<1:\n",
    "                    continue\n",
    "                \n",
    "                #print(str(progress), end=\"\\r\")\n",
    "                print(\"         Computing rank-features: \" + str(int(100*progress/total)) + \"%.\", end='\\r')\n",
    "                # In[312]:\n",
    "\n",
    "\n",
    "\n",
    "                #model.docvecs.most_similar(0)\n",
    "\n",
    "\n",
    "                # In[313]:\n",
    "\n",
    "\n",
    "                #print('Closest in general:')\n",
    "                #for val in model.docvecs.most_similar(i):\n",
    "                #    try:\n",
    "                #        print(documents_ids_A[int(val[0])])\n",
    "                #    except:\n",
    "                #        try:\n",
    "                #            print(documents_ids_B[int(val[0])])\n",
    "                #        except:\n",
    "                #            print(str(val[0]) + \" not found\")\n",
    "\n",
    "\n",
    "                # In[314]:\n",
    "\n",
    "\n",
    "                ##print('Closest in terms of cosine similarity:')\n",
    "                ##vecs = model.docvecs.doctag_syn0[np.array(get_possible_matches(nodeid))]\n",
    "                ##vecs = model.wv[get_possible_matches(nodeid)]\n",
    "                ##x = cosine_similarity(np.array([model.wv[nodeid]]), vecs)\n",
    "                ##x = np.concatenate((x, np.array([get_possible_matches(nodeid)])), axis=0)\n",
    "                ##sorted_x = pd.DataFrame(x).T.sort_values(by=[0], ascending=False)\n",
    "                ##sorted_x.loc[:,'cos_score'] = 0\n",
    "                #ctr = 1\n",
    "                ##sorted_x.columns = ['cos_sim' if col==0 else col for col in sorted_x.columns]\n",
    "                ##sorted_x.columns = ['cos_sim' if col==0 else col for col in sorted_x.columns]\n",
    "                ##sorted_x['cos_sim'] = sorted_x['cos_sim'].astype('float64')\n",
    "                #sorted_x = possible_matches_for_nodeid.sort_values(by=['syntactic_diff'], ascending=False)\n",
    "                #sorted_x.loc[:,'syntax_score'] = 0\n",
    "                #maximum = sorted_x.head(1).src_tgt_angle.values[0]\n",
    "                ##sorted_x.loc[:,'diff_to_max'] = 1.0 - sorted_x.loc[:, 'src_tgt_angle'] / maximum\n",
    "                #for index, row in sorted_x.iterrows():\n",
    "                #    #print(row[1] + \" - \" + str(row['cos_sim']))\n",
    "                #    sorted_x.loc[index, 'syntax_score'] = row['syntax_score'] + 1/ctr\n",
    "                #    ctr += 1\n",
    "\n",
    "\n",
    "                # In[315]:\n",
    "\n",
    "\n",
    "                #print('Closest in terms of Euclidean distance:')print('Closest in terms of Euclidean distance:')\n",
    "                #sorted_x2 = sorted_x\n",
    "                #vecs = model.wv[get_possible_matches(nodeid)]\n",
    "                #x = euclidean_distances(np.array([model.wv[nodeid]]), vecs)\n",
    "                #x = np.concatenate((x, np.array([get_possible_matches(nodeid)])), axis=0)\n",
    "                #sorted_x = pd.DataFrame(x).T.sort_values(by=[0], ascending=True)\n",
    "                #sorted_x = possible_matches_for_nodeid.sort_values(by=['src_tgt_veclen'], ascending=True)\n",
    "                #sorted_x.loc[:,'euclid_score'] = 0\n",
    "                #ctr = 1\n",
    "                ##sorted_x.columns = ['euclid_sim' if col==0 else col for col in sorted_x.columns]\n",
    "                #for index, row in sorted_x.iterrows():\n",
    "                #    #print(row[1] + \" - \" + str(row['euclid_sim']))\n",
    "                #    sorted_x.loc[index, 'euclid_score'] = row['euclid_score'] + 1/ctr\n",
    "                #    ctr += 1\n",
    "\n",
    "\n",
    "\n",
    "                ##print('Closest in terms of syntax:')\n",
    "                #sorted_x3 = sorted_x\n",
    "                ##vecs = model.wv[get_possible_matches(nodeid)]\n",
    "                #def edits(v1, v2s):\n",
    "                #    res = list()\n",
    "                #    v1 = v1.split(\"/\")[-1]\n",
    "                #    for v2 in v2s:\n",
    "                #        v2 = v2.split(\"/\")[-1]\n",
    "                #        res.append(editdistance.eval(v1, v2)/min(len(v1), len(v2)))\n",
    "                #    return np.array([res])\n",
    "                ##x = edits(nodeid, get_possible_matches(nodeid))\n",
    "                ##x = np.concatenate((x, np.array([get_possible_matches(nodeid)])), axis=0)\n",
    "                ##sorted_x = pd.DataFrame(x).T.sort_values(by=[0], ascending=True)\n",
    "                #sorted_x = possible_matches_for_nodeid.sort_values(by=['syntactic_diff'], ascending=True)\n",
    "                #sorted_x.loc[:,'syntax_score'] = 0\n",
    "                #ctr = 1\n",
    "                ##sorted_x.columns = ['syntax_diff' if col==0 else col for col in sorted_x.columns]\n",
    "                #for index, row in sorted_x.iterrows():\n",
    "                #    #print(row[1] + \" - \" + str(row['syntax_diff']))\n",
    "                #    sorted_x.loc[index, 'syntax_score'] = row['syntax_score'] + 1/ctr\n",
    "                #    ctr += 1\n",
    "\n",
    "\n",
    "\n",
    "                #sorted_x3 = sorted_x\n",
    "                ##sorted_x = possible_matches_for_nodeid\n",
    "                ctr = 1\n",
    "                sorted_x = possible_matches_for_nodeid\n",
    "                sorted_x.loc[:,'probability_score'] = 0\n",
    "                sorted_x.loc[:,'probability'] = 0\n",
    "                #print('Closest in terms of output probability:')\n",
    "                for tuple in model.predict_output_word(get_training_material(nodeid), topn=99999999):\n",
    "                    if tuple[0] in possible_matches_for_nodeid.tgt_id.to_list():\n",
    "                        sorted_x.loc[sorted_x.tgt_id==tuple[0], 'probability'] = float(tuple[1])\n",
    "                        sorted_x.loc[sorted_x.tgt_id==tuple[0], 'probability_score'] = 1/ctr\n",
    "                        ctr = ctr + 1\n",
    "\n",
    "\n",
    "                # In[316]:\n",
    "\n",
    "\n",
    "                ##print('Closest in sum:')\n",
    "                ##x = sorted_x[['probability_score','probability']].merge(sorted_x3['euclid_score'].to_frame().merge(sorted_x2, left_index=True, right_index=True), left_index=True, right_index=True)\n",
    "                #x = sorted_x\n",
    "                #x.loc[:,'total_score'] = x['syntax_score'] #x['cos_score'] + x['euclid_score'] + x['probability_score']\n",
    "                #sorted_x = x.sort_values(by=['total_score'], ascending=False)\n",
    "                ##sorted_x.columns = ['tgt_id' if col==1 else col for col in sorted_x.columns]\n",
    "                #for index, row in sorted_x.iterrows():#sorted_x.loc[sorted_x.total_score == max(sorted_x.total_score.values),:].iterrows():\n",
    "                #    matching_pair = pd.DataFrame([sorted_x.loc[index]])\n",
    "                #    matching_pair.loc[:,'src_id'] = nodeid\n",
    "                #    #print(nodeid + \"\\t\" + row[1] + \"\\t\" + str(row['total_score']) + \"\\t\" + str(row['cos_score']) + \"\\t\" + str(row['euclid_score']))\n",
    "                #    matchings = mergedf(matchings, matching_pair)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 left             \r"
     ]
    }
   ],
   "source": [
    "matchings = gs\n",
    "matchings_saved=matchings\n",
    "matchings = matchings.sort_values(by=['src_tgt_angle'], ascending=[False])\n",
    "married_matchings = None\n",
    "ctr = 0\n",
    "while len(matchings) > 0:\n",
    "                ctr += 1\n",
    "                row = matchings.head(1)\n",
    "                married_matchings = mergedf(married_matchings, pd.DataFrame(row))\n",
    "                matchings = matchings.loc[~(matchings.src_id == row.src_id.values[0]) & ~(matchings.tgt_id == row.tgt_id.values[0])]\n",
    "                print(str(len(matchings)) + \" left         \", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_id</th>\n",
       "      <th>tgt_id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>src_0</th>\n",
       "      <th>src_1</th>\n",
       "      <th>src_2</th>\n",
       "      <th>src_3</th>\n",
       "      <th>src_4</th>\n",
       "      <th>src_5</th>\n",
       "      <th>src_6</th>\n",
       "      <th>...</th>\n",
       "      <th>tgt_16</th>\n",
       "      <th>tgt_17</th>\n",
       "      <th>tgt_18</th>\n",
       "      <th>tgt_19</th>\n",
       "      <th>label_y</th>\n",
       "      <th>src_tgt_angle</th>\n",
       "      <th>src_veclen</th>\n",
       "      <th>tgt_veclen</th>\n",
       "      <th>src_tgt_veclen</th>\n",
       "      <th>syntactic_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.34841</td>\n",
       "      <td>0.10036</td>\n",
       "      <td>-0.483223</td>\n",
       "      <td>0.42016</td>\n",
       "      <td>1.08059</td>\n",
       "      <td>1.04136</td>\n",
       "      <td>0.373498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192904</td>\n",
       "      <td>0.50705</td>\n",
       "      <td>0.159629</td>\n",
       "      <td>-0.088608</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/pro...</td>\n",
       "      <td>0.629655</td>\n",
       "      <td>3.46191</td>\n",
       "      <td>1.76442</td>\n",
       "      <td>3.25172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150278</td>\n",
       "      <td>-0.533885</td>\n",
       "      <td>-0.37751</td>\n",
       "      <td>0.530438</td>\n",
       "      <td>1.74181</td>\n",
       "      <td>-0.0206717</td>\n",
       "      <td>-0.778137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211642</td>\n",
       "      <td>0.42159</td>\n",
       "      <td>-0.126236</td>\n",
       "      <td>0.381433</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/pro...</td>\n",
       "      <td>0.622458</td>\n",
       "      <td>3.31778</td>\n",
       "      <td>3.07073</td>\n",
       "      <td>3.56991</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/cla...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.42897</td>\n",
       "      <td>0.226551</td>\n",
       "      <td>-0.238467</td>\n",
       "      <td>-0.10798</td>\n",
       "      <td>0.533734</td>\n",
       "      <td>-0.856782</td>\n",
       "      <td>-0.0982072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.37133</td>\n",
       "      <td>0.0729395</td>\n",
       "      <td>-0.363426</td>\n",
       "      <td>-0.0450809</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/cla...</td>\n",
       "      <td>0.548729</td>\n",
       "      <td>1.72183</td>\n",
       "      <td>5.20912</td>\n",
       "      <td>4.6909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.565257</td>\n",
       "      <td>0.328912</td>\n",
       "      <td>-0.193222</td>\n",
       "      <td>1.00139</td>\n",
       "      <td>0.512926</td>\n",
       "      <td>-0.407326</td>\n",
       "      <td>-0.476968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458737</td>\n",
       "      <td>0.329321</td>\n",
       "      <td>-0.969888</td>\n",
       "      <td>0.522944</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>0.377258</td>\n",
       "      <td>3.46377</td>\n",
       "      <td>3.44134</td>\n",
       "      <td>2.99906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/oldschoolrune...</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.18965</td>\n",
       "      <td>-0.880397</td>\n",
       "      <td>-1.67465</td>\n",
       "      <td>0.816725</td>\n",
       "      <td>0.739996</td>\n",
       "      <td>-1.44058</td>\n",
       "      <td>0.948554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703113</td>\n",
       "      <td>-0.155038</td>\n",
       "      <td>-0.0925703</td>\n",
       "      <td>1.25274</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/darkscape/res...</td>\n",
       "      <td>0.374406</td>\n",
       "      <td>4.14389</td>\n",
       "      <td>4.45372</td>\n",
       "      <td>3.73039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              src_id  \\\n",
       "0  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "1  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "2  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "3  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "4  http://dbkwik.webdatacommons.org/oldschoolrune...   \n",
       "\n",
       "                                              tgt_id prediction     src_0  \\\n",
       "0  http://dbkwik.webdatacommons.org/darkscape/pro...          1  -1.34841   \n",
       "1  http://dbkwik.webdatacommons.org/darkscape/pro...          1  0.150278   \n",
       "2  http://dbkwik.webdatacommons.org/darkscape/cla...          1  -0.42897   \n",
       "3  http://dbkwik.webdatacommons.org/darkscape/res...          1  0.565257   \n",
       "4  http://dbkwik.webdatacommons.org/darkscape/res...          0   0.18965   \n",
       "\n",
       "      src_1     src_2     src_3     src_4      src_5      src_6  ...  \\\n",
       "0   0.10036 -0.483223   0.42016   1.08059    1.04136   0.373498  ...   \n",
       "1 -0.533885  -0.37751  0.530438   1.74181 -0.0206717  -0.778137  ...   \n",
       "2  0.226551 -0.238467  -0.10798  0.533734  -0.856782 -0.0982072  ...   \n",
       "3  0.328912 -0.193222   1.00139  0.512926  -0.407326  -0.476968  ...   \n",
       "4 -0.880397  -1.67465  0.816725  0.739996   -1.44058   0.948554  ...   \n",
       "\n",
       "     tgt_16     tgt_17     tgt_18     tgt_19  \\\n",
       "0  0.192904    0.50705   0.159629  -0.088608   \n",
       "1 -0.211642    0.42159  -0.126236   0.381433   \n",
       "2   0.37133  0.0729395  -0.363426 -0.0450809   \n",
       "3 -0.458737   0.329321  -0.969888   0.522944   \n",
       "4  0.703113  -0.155038 -0.0925703    1.25274   \n",
       "\n",
       "                                             label_y src_tgt_angle src_veclen  \\\n",
       "0  http://dbkwik.webdatacommons.org/darkscape/pro...      0.629655    3.46191   \n",
       "1  http://dbkwik.webdatacommons.org/darkscape/pro...      0.622458    3.31778   \n",
       "2  http://dbkwik.webdatacommons.org/darkscape/cla...      0.548729    1.72183   \n",
       "3  http://dbkwik.webdatacommons.org/darkscape/res...      0.377258    3.46377   \n",
       "4  http://dbkwik.webdatacommons.org/darkscape/res...      0.374406    4.14389   \n",
       "\n",
       "  tgt_veclen src_tgt_veclen syntactic_diff  \n",
       "0    1.76442        3.25172              0  \n",
       "1    3.07073        3.56991              0  \n",
       "2    5.20912         4.6909              0  \n",
       "3    3.44134        2.99906              0  \n",
       "4    4.45372        3.73039              0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = pd.read_csv(origindir+\"gold_standard.csv\",encoding=\"UTF-8\",sep=\"\\t\", header=None)\n",
    "relevants = set(gold[0].to_list()+gold[1].to_list())\n",
    "married_matches = None\n",
    "for index, row in married_matchings.iterrows():\n",
    "        if row['src_id'] in relevants and row['tgt_id'] in relevants:\n",
    "            married_matches = mergedf(married_matches, pd.DataFrame(row).transpose())\n",
    "married_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def create_elem(src_id, tgt_id):\n",
    "    elem = '<map>\\n<Cell>\\n<entity1 rdf:resource=\"'+src_id+'\"/>\\n'\n",
    "    elem = elem + '<entity2 rdf:resource=\"'+tgt_id+'\"/>\\n<relation>=</relation>\\n'\n",
    "    elem = elem + '<measure rdf:datatype=\"xsd:float\">1.0</measure>\\n</Cell>\\n</map>'\n",
    "    return elem\n",
    "\n",
    "matchings_filename =\"mostlysyntaxmarried_matchings.csv\"\n",
    "#married_matches = pd.read_csv(basedir + matchings_filename, sep=\"\\t\", encoding=\"UTF-8\")\n",
    "starttag = '<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<rdf:RDF xmlns=\"http://knowledgeweb.semanticweb.org/heterogeneity/alignment\"\\n  xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\\n  xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\">\\n<Alignment>\\n  <xml>yes</xml>\\n  <level>0</level>\\n  <type>??</type>\\n  <onto1>\\n    <Ontology rdf:about=\"darkscape\">\\n      <location>http://darkscape.wikia.com</location>\\n    </Ontology>\\n  </onto1>\\n  <onto2>\\n    <Ontology rdf:about=\"oldschoolrunescape\">\\n      <location>http://oldschoolrunescape.wikia.com</location>\\n    </Ontology>\\n  </onto2>\\n'\n",
    "endtag = '</Alignment>\\n</rdf:RDF>'\n",
    "os.mkdir(basedir + matchings_filename.replace(\".csv\",\"\"))\n",
    "with open(basedir + matchings_filename.replace(\".csv\",\"\") + str(os.sep) + 'darkscape~oldschoolrunescape~results.xml', \"w+\", encoding=\"UTF-8\") as f:\n",
    "        f.write(starttag)\n",
    "        for index, row in married_matchings.iterrows():\n",
    "            f.write(create_elem(str(row.src_id).replace(\"&\",\"&amp;\"), str(row.tgt_id).replace(\"&\",\"&amp;\"))+\"\\n\")\n",
    "        f.write(endtag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
