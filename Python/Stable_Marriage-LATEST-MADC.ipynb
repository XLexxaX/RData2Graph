{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "pd.options.display.max_colwidth = 500\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_id</th>\n",
       "      <th>tgt_id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>src_0</th>\n",
       "      <th>src_1</th>\n",
       "      <th>src_2</th>\n",
       "      <th>src_3</th>\n",
       "      <th>src_4</th>\n",
       "      <th>src_5</th>\n",
       "      <th>src_6</th>\n",
       "      <th>...</th>\n",
       "      <th>tgt_91</th>\n",
       "      <th>tgt_92</th>\n",
       "      <th>tgt_93</th>\n",
       "      <th>tgt_94</th>\n",
       "      <th>tgt_95</th>\n",
       "      <th>tgt_96</th>\n",
       "      <th>tgt_97</th>\n",
       "      <th>tgt_98</th>\n",
       "      <th>tgt_99</th>\n",
       "      <th>label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/marvel/resource/cyclops</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/dc/resource/cyclops</td>\n",
       "      <td>0</td>\n",
       "      <td>1.465558</td>\n",
       "      <td>-0.082710</td>\n",
       "      <td>-0.745632</td>\n",
       "      <td>-0.786758</td>\n",
       "      <td>0.350929</td>\n",
       "      <td>-0.478478</td>\n",
       "      <td>-0.179442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147990</td>\n",
       "      <td>0.501297</td>\n",
       "      <td>0.094320</td>\n",
       "      <td>0.541944</td>\n",
       "      <td>0.145733</td>\n",
       "      <td>-0.129454</td>\n",
       "      <td>0.269310</td>\n",
       "      <td>0.028970</td>\n",
       "      <td>0.135499</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/dc/resource/cyclops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/marvel/resource/cyclops</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/dc/resource/cyclopes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.465558</td>\n",
       "      <td>-0.082710</td>\n",
       "      <td>-0.745632</td>\n",
       "      <td>-0.786758</td>\n",
       "      <td>0.350929</td>\n",
       "      <td>-0.478478</td>\n",
       "      <td>-0.179442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328086</td>\n",
       "      <td>0.328326</td>\n",
       "      <td>-0.088920</td>\n",
       "      <td>0.335600</td>\n",
       "      <td>0.062955</td>\n",
       "      <td>0.132012</td>\n",
       "      <td>0.375087</td>\n",
       "      <td>-0.037113</td>\n",
       "      <td>-0.025080</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/dc/resource/cyclopes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/marvel/resource/traveler</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/dc/resource/traveler</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.031406</td>\n",
       "      <td>0.184219</td>\n",
       "      <td>-0.881043</td>\n",
       "      <td>-1.067674</td>\n",
       "      <td>0.643378</td>\n",
       "      <td>-0.059030</td>\n",
       "      <td>-0.188607</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211132</td>\n",
       "      <td>0.286894</td>\n",
       "      <td>-0.007575</td>\n",
       "      <td>0.181855</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>0.063304</td>\n",
       "      <td>0.283267</td>\n",
       "      <td>-0.060635</td>\n",
       "      <td>-0.261845</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/dc/resource/traveler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/marvel/resource/category:1942,_october</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/dc/resource/category:1942,_october</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>0.091292</td>\n",
       "      <td>-0.023617</td>\n",
       "      <td>-0.224610</td>\n",
       "      <td>-0.295551</td>\n",
       "      <td>0.535513</td>\n",
       "      <td>-0.041300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210166</td>\n",
       "      <td>0.336384</td>\n",
       "      <td>0.312924</td>\n",
       "      <td>0.376009</td>\n",
       "      <td>0.104327</td>\n",
       "      <td>-0.100973</td>\n",
       "      <td>0.478241</td>\n",
       "      <td>0.323386</td>\n",
       "      <td>0.446639</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/dc/resource/category:1942,_october</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/marvel/resource/ultimates_vol_1_10</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/dc/resource/intimates_vol_1_10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220097</td>\n",
       "      <td>0.148958</td>\n",
       "      <td>0.014681</td>\n",
       "      <td>-0.429959</td>\n",
       "      <td>0.042188</td>\n",
       "      <td>0.023552</td>\n",
       "      <td>0.051817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078353</td>\n",
       "      <td>0.195945</td>\n",
       "      <td>0.507232</td>\n",
       "      <td>0.362378</td>\n",
       "      <td>0.146630</td>\n",
       "      <td>-0.261519</td>\n",
       "      <td>0.617776</td>\n",
       "      <td>0.019280</td>\n",
       "      <td>-0.085587</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/dc/resource/intimates_vol_1_10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    src_id  \\\n",
       "0                 http://dbkwik.webdatacommons.org/marvel/resource/cyclops   \n",
       "1                 http://dbkwik.webdatacommons.org/marvel/resource/cyclops   \n",
       "2                http://dbkwik.webdatacommons.org/marvel/resource/traveler   \n",
       "3  http://dbkwik.webdatacommons.org/marvel/resource/category:1942,_october   \n",
       "4      http://dbkwik.webdatacommons.org/marvel/resource/ultimates_vol_1_10   \n",
       "\n",
       "                                                                tgt_id  \\\n",
       "0                 http://dbkwik.webdatacommons.org/dc/resource/cyclops   \n",
       "1                http://dbkwik.webdatacommons.org/dc/resource/cyclopes   \n",
       "2                http://dbkwik.webdatacommons.org/dc/resource/traveler   \n",
       "3  http://dbkwik.webdatacommons.org/dc/resource/category:1942,_october   \n",
       "4      http://dbkwik.webdatacommons.org/dc/resource/intimates_vol_1_10   \n",
       "\n",
       "   prediction     src_0     src_1     src_2     src_3     src_4     src_5  \\\n",
       "0           0  1.465558 -0.082710 -0.745632 -0.786758  0.350929 -0.478478   \n",
       "1           1  1.465558 -0.082710 -0.745632 -0.786758  0.350929 -0.478478   \n",
       "2           0 -0.031406  0.184219 -0.881043 -1.067674  0.643378 -0.059030   \n",
       "3           0  0.015250  0.091292 -0.023617 -0.224610 -0.295551  0.535513   \n",
       "4           0  0.220097  0.148958  0.014681 -0.429959  0.042188  0.023552   \n",
       "\n",
       "      src_6  \\\n",
       "0 -0.179442   \n",
       "1 -0.179442   \n",
       "2 -0.188607   \n",
       "3 -0.041300   \n",
       "4  0.051817   \n",
       "\n",
       "                                  ...                                   \\\n",
       "0                                 ...                                    \n",
       "1                                 ...                                    \n",
       "2                                 ...                                    \n",
       "3                                 ...                                    \n",
       "4                                 ...                                    \n",
       "\n",
       "     tgt_91    tgt_92    tgt_93    tgt_94    tgt_95    tgt_96    tgt_97  \\\n",
       "0  0.147990  0.501297  0.094320  0.541944  0.145733 -0.129454  0.269310   \n",
       "1 -0.328086  0.328326 -0.088920  0.335600  0.062955  0.132012  0.375087   \n",
       "2 -0.211132  0.286894 -0.007575  0.181855  0.010306  0.063304  0.283267   \n",
       "3 -0.210166  0.336384  0.312924  0.376009  0.104327 -0.100973  0.478241   \n",
       "4 -0.078353  0.195945  0.507232  0.362378  0.146630 -0.261519  0.617776   \n",
       "\n",
       "     tgt_98    tgt_99  \\\n",
       "0  0.028970  0.135499   \n",
       "1 -0.037113 -0.025080   \n",
       "2 -0.060635 -0.261845   \n",
       "3  0.323386  0.446639   \n",
       "4  0.019280 -0.085587   \n",
       "\n",
       "                                                               label_y  \n",
       "0                 http://dbkwik.webdatacommons.org/dc/resource/cyclops  \n",
       "1                http://dbkwik.webdatacommons.org/dc/resource/cyclopes  \n",
       "2                http://dbkwik.webdatacommons.org/dc/resource/traveler  \n",
       "3  http://dbkwik.webdatacommons.org/dc/resource/category:1942,_october  \n",
       "4      http://dbkwik.webdatacommons.org/dc/resource/intimates_vol_1_10  \n",
       "\n",
       "[5 rows x 205 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basedir = \"C:/Users/Alexander/DeepAnyMatch/result_data/MADC_w2v_steps_walklength1_3grams_2019_07_07_15_11_45_607118/\"\n",
    "\n",
    "gs = pd.read_csv(basedir+\"oaei_gold_standard5best.csv\", encoding=\"UTF-8\", sep=\"\\t\", header=None)\n",
    "gs.columns = ['src_id','tgt_id','prediction']\n",
    "embs = pd.read_csv(basedir+\"stratified_embeddings.csv\", encoding=\"UTF-8\", sep=\",\")\n",
    "embs = embs[[col for col in embs.columns if re.match('x\\d+', col) is not None]+['label']]\n",
    "embs.columns = [\"src_\" + str(col) for col in [re.search(\"\\d+\", col).group(0) for col in embs.columns if re.match('x\\d+', col) is not None]] + ['label']\n",
    "gs = gs.merge(embs, left_on=['src_id'], right_on=['label'])\n",
    "embs.columns = [\"tgt_\" + str(col) for col in [re.search(\"\\d+\", col).group(0) for col in embs.columns if re.match('src_\\d+', col) is not None]] + ['label']\n",
    "gs = gs.merge(embs, left_on=['tgt_id'], right_on=['label'])\n",
    "gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oaei_gold_standard3 = pd.read_csv(basedir+\"oaei_gold_standard2.csv_merged.csv\",sep=\"\\t\",encoding=\"UTF-8\")\n",
    "oaei_gold_standard3 = oaei_gold_standard3[['src_id','tgt_id','label']]\n",
    "embs = pd.read_csv(basedir+\"stratified_embeddings.csv\", encoding=\"UTF-8\", sep=\",\")\n",
    "embs = embs[[col for col in embs.columns if re.match('x\\d+', col) is not None]+['label']]\n",
    "embs.columns = [\"src_\" + str(col) for col in [re.search(\"\\d+\", col).group(0) for col in embs.columns if re.match('x\\d+', col) is not None]] + ['label']\n",
    "oaei_gold_standard3 = oaei_gold_standard3.merge(embs, left_on=['src_id'], right_on=['label'])\n",
    "embs.columns = [\"tgt_\" + str(col) for col in [re.search(\"\\d+\", col).group(0) for col in embs.columns if re.match('src_\\d+', col) is not None]] + ['label']\n",
    "oaei_gold_standard3 = oaei_gold_standard3.merge(embs, left_on=['tgt_id'], right_on=['label'])\n",
    "\n",
    "oaei_gold_standard3 = extend_features(oaei_gold_standard3)\n",
    "oaei_gold_standard3['syntactic_diff'] = oaei_gold_standard3.apply(lambda row: jacc(row['src_id'], row['tgt_id']), axis=1)\n",
    "oaei_gold_standard3['plus_diff'] = oaei_gold_standard3.apply(lambda row: lev(row['src_id'], row['tgt_id']), axis=1)\n",
    "oaei_gold_standard3 = oaei_gold_standard3.drop(['label'], axis=1)\n",
    "oaei_gold_standard3.rename({'label_x':'label'}, inplace=True, axis='columns')\n",
    "oaei_gold_standard3 = oaei_gold_standard3.drop(['label_y'], axis=1)\n",
    "oaei_gold_standard3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "origindir = \"C:/Users/Alexander/rdata2graph/data/madc/\"\n",
    "labels1 = dict()\n",
    "categories1 = dict()\n",
    "with open(origindir+\"graph_triples_ma.nt\", encoding=\"UTF-8\", mode=\"r\") as f:\n",
    "    for line in f:\n",
    "        line = str(line).lower()\n",
    "        if '<http://www.w3.org/2000/01/rdf-schema#label>' in line:\n",
    "            line = line.replace(\"<\",\"\").replace(\">\",\"\").replace(\" .\\n\",\"\").split(\" http://www.w3.org/2000/01/rdf-schema#label \")\n",
    "            labels1[line[0]] = line[1]\n",
    "        if '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>' in line:\n",
    "            line = line.replace(\"<\",\"\").replace(\">\",\"\").replace(\" .\\n\",\"\").split(\" http://www.w3.org/1999/02/22-rdf-syntax-ns#type \")\n",
    "            if line[1] not in ['http://www.w3.org/2002/07/owl#class','http://www.w3.org/1999/02/22-rdf-syntax-ns#property']:\n",
    "                categories1[line[0]] = 'resource'\n",
    "            else:\n",
    "                categories1[line[0]] = line[1]\n",
    "labels2 = dict()\n",
    "categories2 = dict()\n",
    "with open(origindir+\"graph_triples_dc.nt\", encoding=\"UTF-8\", mode=\"r\") as f:\n",
    "    for line in f:\n",
    "        line = str(line).lower()\n",
    "        if '<http://www.w3.org/2000/01/rdf-schema#label>' in line:\n",
    "            line = line.replace(\"<\",\"\").replace(\">\",\"\").replace(\" .\\n\",\"\").split(\" http://www.w3.org/2000/01/rdf-schema#label \")\n",
    "            labels2[line[0]] = line[1]\n",
    "        if '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>' in line:\n",
    "            line = line.replace(\"<\",\"\").replace(\">\",\"\").replace(\" .\\n\",\"\").split(\" http://www.w3.org/1999/02/22-rdf-syntax-ns#type \")\n",
    "            if line[1] not in ['http://www.w3.org/2002/07/owl#class','http://www.w3.org/1999/02/22-rdf-syntax-ns#property']:\n",
    "                categories2[line[0]] = 'resource'\n",
    "            else:\n",
    "                categories2[line[0]] = line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11062"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.loc[:,'src_category'] = 'resource'\n",
    "gs.loc[:,'tgt_category'] = 'resource'\n",
    "for index, row in gs.iterrows():\n",
    "    try:\n",
    "        gs.loc[index, 'src_category'] = categories1[row['src_id']]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        gs.loc[index, 'tgt_category'] = categories2[row['tgt_id']]\n",
    "    except KeyError:\n",
    "        pass\n",
    "gs = gs.loc[gs.src_category == gs.tgt_category]\n",
    "len(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import *\n",
    "def extend_features(df):\n",
    "    src_pattern = \"src_\\d+\"\n",
    "    tgt_pattern = \"tgt_\\d+\"\n",
    "    src_dim = int(len([elem for elem in [re.match(src_pattern, elem) is not None for elem in df.columns.values.tolist()] if elem==True]))\n",
    "    tgt_dim = int(len([elem for elem in [re.match(tgt_pattern, elem) is not None for elem in df.columns.values.tolist()] if elem==True]))\n",
    "\n",
    "\n",
    "    def dotproduct(v1, v2):\n",
    "        result = list()\n",
    "        for i in range(len(v1)):\n",
    "            result.append([np.dot(v1[i], v2[i])])\n",
    "        return np.array(result)\n",
    "\n",
    "    def length(v):\n",
    "        return np.sqrt(dotproduct(v, v))\n",
    "\n",
    "    def angle(v1, v2):\n",
    "        return np.arctan(dotproduct(v1, v2) / (length(v1) * length(v2)))\n",
    "\n",
    "    a = np.array(df[[\"src_\" + str(i) for i in range(src_dim)]].values.tolist())\n",
    "    b = np.array(df[[\"tgt_\" + str(i) for i in range(tgt_dim)]].values.tolist())\n",
    "    print(\".\")\n",
    "    df['src_tgt_angle'] = paired_cosine_distances(a, b)\n",
    "    print(\".\")\n",
    "    src_origin = np.full((len(df), src_dim), 0.0000001)\n",
    "    tgt_origin = np.full((len(df), tgt_dim), 0.0000001)\n",
    "    df['src_angle_to_origin'] = paired_cosine_distances(tgt_origin,a)\n",
    "    #print(\".\")\n",
    "    df['tgt_angle_to_origin'] = paired_cosine_distances(src_origin,b)\n",
    "    df['src_veclen'] = length(a)\n",
    "    df['tgt_veclen'] = length(b)\n",
    "    df['src_tgt_veclen'] = paired_euclidean_distances(a,b)#.diagonal()#length(a-b)\n",
    "    df.head()\n",
    "    \n",
    "    df.fillna(0, inplace = True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11062"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = extend_features(gs)\n",
    "#oaei_gold_standard3 = extend_features(oaei_gold_standard3)\n",
    "len(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "memo = {}\n",
    "\n",
    "def jacc(s,t, n=3):\n",
    "    s = labels1[s]\n",
    "    t = labels2[t]\n",
    "    t = set([t[i:i+n] for i in range(len(t)-n+1)])\n",
    "    s = set([s[i:i+n] for i in range(len(s)-n+1)])\n",
    "    return 1-len([gram for gram in s if gram in t])/max(len(s), len(t))\n",
    "\n",
    "def lev(s,t, n=3):\n",
    "    s = labels1[s]\n",
    "    t = labels2[t]\n",
    "    return levenshtein(s,t)/max(len(s),len(t))\n",
    "    \n",
    "def levenshtein(s, t):\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    cost = 0 if s[-1] == t[-1] else 1\n",
    "\n",
    "    i1 = (s[:-1], t)\n",
    "    if not i1 in memo:\n",
    "        memo[i1] = levenshtein(*i1)\n",
    "    i2 = (s, t[:-1])\n",
    "    if not i2 in memo:\n",
    "        memo[i2] = levenshtein(*i2)\n",
    "    i3 = (s[:-1], t[:-1])\n",
    "    if not i3 in memo:\n",
    "        memo[i3] = levenshtein(*i3)\n",
    "    res = min([memo[i1]+1, memo[i2]+1, memo[i3]+cost])\n",
    "\n",
    "    return res\n",
    "gs['syntactic_diff'] = gs.apply(lambda row: jacc(row['src_id'], row['tgt_id']), axis=1)\n",
    "gs['plus_diff'] = gs.apply(lambda row: lev(row['src_id'], row['tgt_id']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_id</th>\n",
       "      <th>tgt_id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>src_0</th>\n",
       "      <th>src_1</th>\n",
       "      <th>src_2</th>\n",
       "      <th>src_3</th>\n",
       "      <th>src_4</th>\n",
       "      <th>src_5</th>\n",
       "      <th>src_6</th>\n",
       "      <th>...</th>\n",
       "      <th>tgt_category</th>\n",
       "      <th>src_tgt_angle</th>\n",
       "      <th>src_angle_to_origin</th>\n",
       "      <th>tgt_angle_to_origin</th>\n",
       "      <th>src_veclen</th>\n",
       "      <th>tgt_veclen</th>\n",
       "      <th>src_tgt_veclen</th>\n",
       "      <th>syntactic_diff</th>\n",
       "      <th>plus_diff</th>\n",
       "      <th>total_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/marvel/property/creators</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/dc/property/creators</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12029</td>\n",
       "      <td>0.421354</td>\n",
       "      <td>0.028653</td>\n",
       "      <td>-0.078129</td>\n",
       "      <td>-0.440138</td>\n",
       "      <td>0.550072</td>\n",
       "      <td>0.131631</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.w3.org/1999/02/22-rdf-syntax-ns#property</td>\n",
       "      <td>0.729241</td>\n",
       "      <td>1.081051</td>\n",
       "      <td>0.984249</td>\n",
       "      <td>3.998457</td>\n",
       "      <td>6.446167</td>\n",
       "      <td>6.601759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>http://dbkwik.webdatacommons.org/marvel/property/creators</td>\n",
       "      <td>http://dbkwik.webdatacommons.org/dc/property/creator</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12029</td>\n",
       "      <td>0.421354</td>\n",
       "      <td>0.028653</td>\n",
       "      <td>-0.078129</td>\n",
       "      <td>-0.440138</td>\n",
       "      <td>0.550072</td>\n",
       "      <td>0.131631</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.w3.org/1999/02/22-rdf-syntax-ns#property</td>\n",
       "      <td>0.780873</td>\n",
       "      <td>1.081051</td>\n",
       "      <td>1.050720</td>\n",
       "      <td>3.998457</td>\n",
       "      <td>5.608273</td>\n",
       "      <td>6.132926</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       src_id  \\\n",
       "63  http://dbkwik.webdatacommons.org/marvel/property/creators   \n",
       "66  http://dbkwik.webdatacommons.org/marvel/property/creators   \n",
       "\n",
       "                                                   tgt_id  prediction  \\\n",
       "63  http://dbkwik.webdatacommons.org/dc/property/creators           0   \n",
       "66   http://dbkwik.webdatacommons.org/dc/property/creator           1   \n",
       "\n",
       "      src_0     src_1     src_2     src_3     src_4     src_5     src_6  \\\n",
       "63  0.12029  0.421354  0.028653 -0.078129 -0.440138  0.550072  0.131631   \n",
       "66  0.12029  0.421354  0.028653 -0.078129 -0.440138  0.550072  0.131631   \n",
       "\n",
       "       ...                                              tgt_category  \\\n",
       "63     ...       http://www.w3.org/1999/02/22-rdf-syntax-ns#property   \n",
       "66     ...       http://www.w3.org/1999/02/22-rdf-syntax-ns#property   \n",
       "\n",
       "    src_tgt_angle  src_angle_to_origin  tgt_angle_to_origin  src_veclen  \\\n",
       "63       0.729241             1.081051             0.984249    3.998457   \n",
       "66       0.780873             1.081051             1.050720    3.998457   \n",
       "\n",
       "    tgt_veclen  src_tgt_veclen  syntactic_diff  plus_diff  total_score  \n",
       "63    6.446167        6.601759        0.000000   0.000000            0  \n",
       "66    5.608273        6.132926        0.272727   0.076923            0  \n",
       "\n",
       "[2 rows x 216 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.loc[gs.src_id=='http://dbkwik.webdatacommons.org/marvel/property/creators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier \n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "##oaei_gold_standard3 = pd.read_csv(basedir+\"oaei_gold_standard2.csv_merged.csv\",sep=\"\\t\",encoding=\"UTF-8\")\n",
    "#\n",
    "#cols = [col for col in oaei_gold_standard3.columns if col not in ['plus_diff','syntactic_diff','label','Unnamed: 0','src_id','tgt_id','src_category','tgt_category']]#['src_tgt_angle', 'src_tgt_veclen', 'plus_diff', 'syntactic_diff']\n",
    "#X, y = oaei_gold_standard3[cols], oaei_gold_standard3.label\n",
    "#clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr', class_weight={1:0.9,0:0.1}).fit(X, y)\n",
    "##XGBClassifier().fit(X, y)\n",
    "##LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr', class_weight={1:0.9,0:0.1}).fit(X, y)\n",
    "#        #random_state=0, solver='lbfgs', multi_class='ovr', class_weight={1:0.1,0:0.9}).fit(X, y)\n",
    "#\n",
    "#X = gs[cols]\n",
    "#matchings = gs.loc[clf.predict(X)==1]\n",
    "#matchings.loc[:,'confidence'] = clf.predict_proba(matchings[cols])[:,1]\n",
    "#len(matchings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5915"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchings = gs.loc[gs.plus_diff<0.1]\n",
    "len(matchings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5915"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = matchings\n",
    "len(matchings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(gs.src_id))\n",
    "from gensim.models import Doc2Vec, Word2Vec\n",
    "model = Word2Vec.load(basedir+\"w2v.model\")\n",
    "def get_training_material(nid):\n",
    "            res = list()\n",
    "            with open(basedir+\"w2v_training_material.csv\", mode=\"r\", encoding=\"UTF-8\") as f:\n",
    "                for line in f:\n",
    "                    if nodeid in line.split(\" \"):\n",
    "                        for w in line.split(\" \"):\n",
    "                            yield w\n",
    "\n",
    "def mergedf(df1, df2):\n",
    "            if df1 is None:\n",
    "                return df2\n",
    "            else:\n",
    "                return df1.append(df2, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.loc[:,'total_score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Computing rank-features: 0%.\r",
      "         Computing rank-features: 0%.\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alexander\\anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Computing rank-features: 99%.\r"
     ]
    }
   ],
   "source": [
    "progress = 0\n",
    "matchings = None\n",
    "total = len(set(gs.src_id))\n",
    "for nodeid in set(gs.src_id):#.union(gs.tgt_id)\n",
    "                possible_matches_for_nodeid = gs.loc[(gs.src_id==nodeid) ]\n",
    "        \n",
    "                #possible_matches.loc[((possible_matches.src_id==nodeid) & (possible_matches.tgt_id.isin(get_possible_matches(nodeid))))]\n",
    "\n",
    "\n",
    "\n",
    "                progress += 1\n",
    "                if len(possible_matches_for_nodeid)<1:\n",
    "                    continue\n",
    "                elif len(possible_matches_for_nodeid) == 1:\n",
    "                    matching_pair = possible_matches_for_nodeid.head(1)\n",
    "                    matchings = mergedf(matchings, matching_pair)\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "                #print(str(progress), end=\"\\r\")\n",
    "                print(\"         Computing rank-features: \" + str(int(100*progress/total)) + \"%.\", end='\\r')\n",
    "                # In[312]:\n",
    "\n",
    "\n",
    "\n",
    "                #model.docvecs.most_similar(0)\n",
    "\n",
    "\n",
    "                # In[313]:\n",
    "\n",
    "\n",
    "                #print('Closest in general:')\n",
    "                #for val in model.docvecs.most_similar(i):\n",
    "                #    try:\n",
    "                #        print(documents_ids_A[int(val[0])])\n",
    "                #    except:\n",
    "                #        try:\n",
    "                #            print(documents_ids_B[int(val[0])])\n",
    "                #        except:\n",
    "                #            print(str(val[0]) + \" not found\")\n",
    "\n",
    "\n",
    "                # In[314]:\n",
    "\n",
    "\n",
    "                ##print('Closest in terms of cosine similarity:')\n",
    "                ##vecs = model.docvecs.doctag_syn0[np.array(get_possible_matches(nodeid))]\n",
    "                ##vecs = model.wv[get_possible_matches(nodeid)]\n",
    "                ##x = cosine_similarity(np.array([model.wv[nodeid]]), vecs)\n",
    "                ##x = np.concatenate((x, np.array([get_possible_matches(nodeid)])), axis=0)\n",
    "                ##sorted_x = pd.DataFrame(x).T.sort_values(by=[0], ascending=False)\n",
    "                ##sorted_x.loc[:,'cos_score'] = 0\n",
    "                ctr = 1\n",
    "                ##sorted_x.columns = ['cos_sim' if col==0 else col for col in sorted_x.columns]\n",
    "                ##sorted_x.columns = ['cos_sim' if col==0 else col for col in sorted_x.columns]\n",
    "                ##sorted_x['cos_sim'] = sorted_x['cos_sim'].astype('float64')\n",
    "                sorted_x = possible_matches_for_nodeid.sort_values(by=['src_tgt_angle'], ascending=True)\n",
    "                sorted_x.loc[:,'cos_score'] = 0\n",
    "                #maximum = sorted_x.head(1).src_tgt_angle.values[0]\n",
    "                #sorted_x.loc[:,'diff_to_max'] = 1.0 - sorted_x.loc[:, 'src_tgt_angle'] / maximum\n",
    "                for index, row in sorted_x.iterrows():\n",
    "                    #print(row[1] + \" - \" + str(row['cos_sim']))\n",
    "                    sorted_x.loc[index, 'cos_score'] = row['cos_score'] + 1/ctr\n",
    "                    ctr += 1\n",
    "                #sorted_x = possible_matches_for_nodeid.sort_values(by=['confidence'], ascending=False)\n",
    "                sorted_x.loc[:,'conficence'] = 0 \n",
    "                sorted_x.loc[:,'confidence_score'] = 0 \n",
    "                #ctr = 1\n",
    "                #for index, row in sorted_x.iterrows():\n",
    "                #    sorted_x.loc[index, 'confidence_score'] = row['confidence_score'] + 1/ctr\n",
    "                #    ctr += 1\n",
    "\n",
    "                # In[315]:\n",
    "\n",
    "\n",
    "                ##print('Closest in terms of Euclidean distance:')print('Closest in terms of Euclidean distance:')\n",
    "                #sorted_x2 = sorted_x\n",
    "                ##vecs = model.wv[get_possible_matches(nodeid)]\n",
    "                ##x = euclidean_distances(np.array([model.wv[nodeid]]), vecs)\n",
    "                ##x = np.concatenate((x, np.array([get_possible_matches(nodeid)])), axis=0)\n",
    "                ##sorted_x = pd.DataFrame(x).T.sort_values(by=[0], ascending=True)\n",
    "                sorted_x = sorted_x.sort_values(by=['src_tgt_veclen'], ascending=True)\n",
    "                sorted_x.loc[:,'euclid_score'] = 0\n",
    "                ctr = 1\n",
    "                ##sorted_x.columns = ['euclid_sim' if col==0 else col for col in sorted_x.columns]\n",
    "                for index, row in sorted_x.iterrows():\n",
    "                    #print(row[1] + \" - \" + str(row['euclid_sim']))\n",
    "                    sorted_x.loc[index, 'euclid_score'] = row['euclid_score'] + 1/ctr\n",
    "                    ctr += 1\n",
    "\n",
    "\n",
    "\n",
    "                #print('Closest in terms of syntax:')\n",
    "                sorted_x2 = sorted_x\n",
    "                #vecs = model.wv[get_possible_matches(nodeid)]\n",
    "                def edits(v1, v2s):\n",
    "                    res = list()\n",
    "                    v1 = v1.split(\"/\")[-1]\n",
    "                    for v2 in v2s:\n",
    "                        v2 = v2.split(\"/\")[-1]\n",
    "                        res.append(editdistance.eval(v1, v2)/min(len(v1), len(v2)))\n",
    "                    return np.array([res])\n",
    "                #x = edits(nodeid, get_possible_matches(nodeid))\n",
    "                #x = np.concatenate((x, np.array([get_possible_matches(nodeid)])), axis=0)\n",
    "                #sorted_x = pd.DataFrame(x).T.sort_values(by=[0], ascending=True)\n",
    "                sorted_x = possible_matches_for_nodeid.sort_values(by=['syntactic_diff'], ascending=True)\n",
    "                sorted_x.loc[:,'syntax_score'] = 0\n",
    "                ctr = 1\n",
    "                sorted_x.columns = ['syntax_diff' if col==0 else col for col in sorted_x.columns]\n",
    "                #for index, row in sorted_x.iterrows():\n",
    "                    #print(row[1] + \" - \" + str(row['syntax_diff']))\n",
    "                #    sorted_x.loc[index, 'syntax_score'] = row['syntax_score'] + 1/ctr\n",
    "                #    ctr += 1\n",
    "\n",
    "\n",
    "\n",
    "                sorted_x3 = sorted_x\n",
    "                #o1 = get_training_material(nodeid)\n",
    "                #inverted_dict = dict()\n",
    "                #for tgt_id in possible_matches_for_nodeid.tgt_id.to_list():\n",
    "                #    inverted_dict[tgt_id] = [tgt_id]\n",
    "                #    for word in get_training_material(tgt_id):\n",
    "                #        if word in inverted_dict.keys():\n",
    "                #            inverted_dict[word].append(tgt_id)\n",
    "                #        else:\n",
    "                #            inverted_dict[word] = [tgt_id]\n",
    "\n",
    "                #tgt_scores = dict()\n",
    "                #for tgt_id in possible_matches_for_nodeid.tgt_id.to_list():\n",
    "                #    tgt_scores[tgt_id]=0\n",
    "\n",
    "                #for tupl in model.predict_output_word(o1, topn=99999999999999):\n",
    "                #    if tupl[0] in inverted_dict.keys():\n",
    "                #        for tgt_id in inverted_dict[tupl[0]]:\n",
    "                #            tgt_scores[tgt_id] = tgt_scores[tgt_id] + tupl[1]\n",
    "                sorted_x.loc[:,'probability'] = 0\n",
    "                sorted_x.loc[:,'probability_score'] = 0\n",
    "                #ctr=1\n",
    "                #for item in sorted(tgt_scores.items(), key = lambda kv:(kv[1], kv[0]), reverse=True):\n",
    "                #    sorted_x.loc[sorted_x.tgt_id==item[0],'probability_score'] = 1/ctr\n",
    "                #    sorted_x.loc[sorted_x.tgt_id==item[0],'probability'] = float(item[1])\n",
    "                #    ctr += 1\n",
    "\n",
    "                # In[316]:\n",
    "\n",
    "\n",
    "                #print('Closest in sum:')\n",
    "                #sorted_x[['probability_score','probability']].merge(..., left_index=True, right_index=True)\n",
    "                x = sorted_x[['probability_score','probability']].merge(sorted_x3['syntax_score'].to_frame().merge(sorted_x2, left_index=True, right_index=True), left_index=True, right_index=True)\n",
    "                x.loc[:,'total_score'] = x['syntax_score'] + x['euclid_score'] + x['probability_score'] + x['confidence_score'] + x['cos_score']\n",
    "                sorted_x = x.sort_values(by=['total_score'], ascending=False)\n",
    "                ##sorted_x.columns = ['tgt_id' if col==1 else col for col in sorted_x.columns]\n",
    "                for index, row in sorted_x.iterrows():#sorted_x.loc[sorted_x.total_score == max(sorted_x.total_score.values),:].iterrows():\n",
    "                    matching_pair = pd.DataFrame([sorted_x.loc[index]])\n",
    "                    matching_pair.loc[:,'src_id'] = nodeid\n",
    "                    #print(nodeid + \"\\t\" + row[1] + \"\\t\" + str(row['total_score']) + \"\\t\" + str(row['cos_score']) + \"\\t\" + str(row['euclid_score']))\n",
    "                    matchings = mergedf(matchings, matching_pair)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def create_elem(src_id, tgt_id):\n",
    "    elem = '<map>\\n<Cell>\\n<entity1 rdf:resource=\"'+src_id+'\"/>\\n'\n",
    "    elem = elem + '<entity2 rdf:resource=\"'+tgt_id+'\"/>\\n<relation>=</relation>\\n'\n",
    "    elem = elem + '<measure rdf:datatype=\"xsd:float\">1.0</measure>\\n</Cell>\\n</map>'\n",
    "    return elem\n",
    "\n",
    "matchings_filename =\"MADC_ML.csv\"\n",
    "#married_matches = pd.read_csv(\"C:/Users/Alexander/rdata2graph/data/sap_hilti_data/oaei_gold_standard1best.csv\", sep=\"\\t\", encoding=\"UTF-8\")\n",
    "#married_matches.columns=['src_id','tgt_id','label']\n",
    "starttag = '<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<rdf:RDF xmlns=\"http://knowledgeweb.semanticweb.org/heterogeneity/alignment\"\\n  xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\\n  xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\">\\n<Alignment>\\n  <xml>yes</xml>\\n  <level>0</level>\\n  <type>??</type>\\n  <onto1>\\n    <Ontology rdf:about=\"darkscape\">\\n      <location>http://darkscape.wikia.com</location>\\n    </Ontology>\\n  </onto1>\\n  <onto2>\\n    <Ontology rdf:about=\"oldschoolrunescape\">\\n      <location>http://oldschoolrunescape.wikia.com</location>\\n    </Ontology>\\n  </onto2>\\n'\n",
    "endtag = '</Alignment>\\n</rdf:RDF>'\n",
    "#os.mkdir(basedir + matchings_filename.replace(\".csv\",\"\"))\n",
    "with open(basedir + matchings_filename.replace(\".csv\",\"\") + str(os.sep) + 'darkscape~oldschoolrunescape~results.xml', \"w+\", encoding=\"UTF-8\") as f:\n",
    "        f.write(starttag)\n",
    "        for index, row in matchings.iterrows():\n",
    "            f.write(create_elem(str(row.src_id).replace(\"&\",\"&amp;\"), str(row.tgt_id).replace(\"&\",\"&amp;\"))+\"\\n\")\n",
    "        f.write(endtag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matchings = matchings_saved\n",
    "#matchings = gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 left        \r"
     ]
    }
   ],
   "source": [
    "matchings_saved=matchings\n",
    "matchings = matchings.sort_values(by=['syntactic_diff','syntactic_diff'], ascending=[True, True])\n",
    "married_matchings = None\n",
    "ctr = 0\n",
    "while len(matchings) > 0:\n",
    "                ctr += 1\n",
    "                row = matchings.head(1)\n",
    "                married_matchings = mergedf(married_matchings, pd.DataFrame(row))\n",
    "                matchings = matchings.loc[~(matchings.src_id == row.src_id.values[0]) & ~(matchings.tgt_id == row.tgt_id.values[0])]\n",
    "                print(str(len(matchings)) + \" left     \", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def create_elem(src_id, tgt_id):\n",
    "    elem = '<map>\\n<Cell>\\n<entity1 rdf:resource=\"'+src_id+'\"/>\\n'\n",
    "    elem = elem + '<entity2 rdf:resource=\"'+tgt_id+'\"/>\\n<relation>=</relation>\\n'\n",
    "    elem = elem + '<measure rdf:datatype=\"xsd:float\">1.0</measure>\\n</Cell>\\n</map>'\n",
    "    return elem\n",
    "\n",
    "matchings_filename =\"MADC_MARRIED_Syntax_2.csv\"\n",
    "#married_matches = pd.read_csv(basedir + matchings_filename, sep=\"\\t\", encoding=\"UTF-8\")\n",
    "starttag = '<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<rdf:RDF xmlns=\"http://knowledgeweb.semanticweb.org/heterogeneity/alignment\"\\n  xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\\n  xmlns:xsd=\"http://www.w3.org/2001/XMLSchema#\">\\n<Alignment>\\n  <xml>yes</xml>\\n  <level>0</level>\\n  <type>??</type>\\n  <onto1>\\n    <Ontology rdf:about=\"darkscape\">\\n      <location>http://darkscape.wikia.com</location>\\n    </Ontology>\\n  </onto1>\\n  <onto2>\\n    <Ontology rdf:about=\"oldschoolrunescape\">\\n      <location>http://oldschoolrunescape.wikia.com</location>\\n    </Ontology>\\n  </onto2>\\n'\n",
    "endtag = '</Alignment>\\n</rdf:RDF>'\n",
    "os.mkdir(basedir + matchings_filename.replace(\".csv\",\"\"))\n",
    "with open(basedir + matchings_filename.replace(\".csv\",\"\") + str(os.sep) + 'darkscape~oldschoolrunescape~results.xml', \"w+\", encoding=\"UTF-8\") as f:\n",
    "        f.write(starttag)\n",
    "        for index, row in married_matchings.iterrows():\n",
    "            f.write(create_elem(str(row.src_id).replace(\"&\",\"&amp;\"), str(row.tgt_id).replace(\"&\",\"&amp;\"))+\"\\n\")\n",
    "        f.write(endtag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
